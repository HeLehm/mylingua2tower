# mylingua two tower model

## Introduction

## TODO
- [ ] add more comments
- [ ] GloVe unk token
- [ ] GloVe lower dimension
- [ ] inference model
- [ ] save and load with optimizer etc
- [ ] save hparams
- [ ] use Fastformer

## Note
There used to be a pytorch version but it was never finished...

## References
word embedding: https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76
https://nlp.stanford.edu/projects/glove/

fastformer: https://github.com/wuch15/Fastformer

2 tower model:
https://aclanthology.org/D19-1671.pdf

MIND:
https://msnews.github.io
https://github.com/microsoft/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb


## Installation
https://github.com/Blosc/c-blosc
https://github.com/Blosc/bcolz
